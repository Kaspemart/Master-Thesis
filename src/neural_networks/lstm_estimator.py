"""
--------------------------------------------------------------------------------------------------------------------------------------
- LSTM-Based Parameter Estimator for Basic Stochastic Volatility Model
--------------------------------------------------------------------------------------------------------------------------------------
PURPOSE:
This module implements a neural network (LSTM) that learns to estimate the parameters
(φ, σ_v) of the basic SV model directly from observed return sequences.

This is an example of amortized inference: the network learns a general mapping from
returns → parameters, providing instant estimates after training, unlike classical
methods that require costly optimization for each new dataset.
--------------------------------------------------------------------------------------------------------------------------------------
ARCHITECTURE:
Input:  Return sequence (T timesteps) → Shape: (batch_size, T)
    ↓
LSTM layers: Extract temporal patterns and volatility clustering
    ↓
Dense layers: Map LSTM output to parameter space
    ↓
Output: Estimated parameters [φ, σ_v] → Shape: (batch_size, 2)
--------------------------------------------------------------------------------------------------------------------------------------
TRAINING:
- Loss function: MSE on normalized parameters
- Optimizer: Adam with learning rate scheduling
- Validation: Early stopping based on validation loss
- Checkpointing: Save best model during training
--------------------------------------------------------------------------------------------------------------------------------------
"""


# IMPORTS:
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
import logging
# ---------------------------------------------------------------------------------------------------------------------------


# Setting up module logger
logger = logging.getLogger(__name__)


class SVParameterDataset(Dataset[tuple[torch.Tensor, torch.Tensor]]):
    """
    PyTorch Dataset for SV model parameter estimation.
    
    This dataset wraps the synthetic data generated by BasicSVDataGenerator
    and provides it in a format suitable for PyTorch training.
    
    Parameters
    ----------
    returns : np.ndarray
        Return sequences of shape (n_samples, sequence_length).
    parameters : np.ndarray
        True parameters of shape (n_samples, 2) where columns are [φ, σ_v].
    normalize_returns : bool, default=True
        Whether to standardize returns (zero mean, unit variance).
        Recommended for neural network training.
    normalize_parameters : bool, default=False
        Whether to normalize parameters to [0, 1] range.
        If False, parameters are used as-is (they're already in reasonable ranges).
    
    Examples
    --------
    >>> from src.data.synthetic.basic_sv import BasicSVDataGenerator
    >>> generator = BasicSVDataGenerator(seed=42)
    >>> data = generator.generate(1000)
    >>> 
    >>> dataset = SVParameterDataset(
    ...     returns=data['returns'],
    ...     parameters=data['parameters']
    ... )
    >>> 
    >>> # Use with DataLoader
    >>> from torch.utils.data import DataLoader
    >>> loader = DataLoader(dataset, batch_size=32, shuffle=True)
    >>> for returns, params in loader:
    ...     print(returns.shape)  # (32, 252)
    ...     print(params.shape)  # (32, 2)
    """
    
    def __init__(
        self,
        returns: np.ndarray,
        parameters: np.ndarray,
        normalize_returns: bool = True,
        normalize_parameters: bool = False
    ) -> None:
        """Initialize the dataset."""
        self.returns = returns.astype(np.float32)
        self.parameters = parameters.astype(np.float32)
        
        # Computing normalization statistics
        if normalize_returns:
            self.return_mean = float(np.mean(returns))
            self.return_std = float(np.std(returns))
            # Normalizing returns
            self.returns = (self.returns - self.return_mean) / self.return_std
        else:
            self.return_mean = 0.0
            self.return_std = 1.0
        
        if normalize_parameters:
            # Normalizing parameters to [0, 1] range
            self.param_min = parameters.min(axis=0)
            self.param_max = parameters.max(axis=0)
            self.parameters = (self.parameters - self.param_min) / (self.param_max - self.param_min)
        else:
            self.param_min = None
            self.param_max = None
        
        logger.info(f"Created dataset with {len(self)} samples")
        if normalize_returns:
            logger.info(f"Returns normalized: mean={self.return_mean:.4f}, std={self.return_std:.4f}")
    
    def __len__(self) -> int:
        """Return the number of samples."""
        return len(self.returns)
    
    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:
        """
        Get a single sample.
        
        Parameters
        ----------
        idx : int
            Sample index.
        
        Returns
        -------
        returns : torch.Tensor
            Return sequence of shape (sequence_length,).
        parameters : torch.Tensor
            True parameters of shape (2,) where elements are [φ, σ_v].
        """
        return (
            torch.from_numpy(self.returns[idx]),  # type: ignore[arg-type]
            torch.from_numpy(self.parameters[idx])  # type: ignore[arg-type]
        )


class LSTMParameterEstimator(nn.Module):
    """
    LSTM-based neural network for estimating SV model parameters from return sequences.
    
    This network learns to map observed return sequences directly to the underlying
    model parameters (φ, σ_v), performing amortized inference. Once trained, it
    provides instant parameter estimates without requiring optimization.
    
    Architecture:
    - Input: Return sequence (T timesteps)
    - LSTM layers: Extract temporal dependencies and volatility patterns
    - Dense layers: Map to parameter space
    - Output: Estimated [φ, σ_v]
    
    Parameters
    ----------
    input_size : int, default=1
        Number of features per timestep (1 for returns).
    hidden_size : int, default=128
        Number of hidden units in LSTM layers.
        Larger values capture more complex patterns but increase computation.
    num_layers : int, default=2
        Number of LSTM layers.
        More layers can learn hierarchical patterns but may overfit.
    dropout : float, default=0.2
        Dropout probability for regularization.
        Set to 0.0 to disable dropout.
    sequence_length : int, default=252
        Length of input sequences (number of timesteps).
    
    Attributes
    ----------
    lstm : nn.LSTM
        LSTM layers for sequence processing
    fc_layers : nn.Sequential
        Fully connected layers for parameter estimation
    output_size : int
        Number of output parameters (always 2: φ and σ_v)
    
    Examples
    --------
    >>> model = LSTMParameterEstimator(hidden_size=128, num_layers=2)
    >>> 
    >>> # Forward pass
    >>> returns = torch.randn(32, 252)  # batch_size=32, sequence_length=252
    >>> predictions = model(returns)
    >>> predictions.shape
    torch.Size([32, 2])
    >>> 
    >>> # Predictions are [phi, sigma_v]
    >>> phi_est = predictions[:, 0]
    >>> sigma_v_est = predictions[:, 1]
    
    Notes
    -----
    The network architecture is:
    1. LSTM layers process the sequence (capturing volatility clustering)
    2. Last LSTM hidden state is extracted
    3. Dense layers map to 2D parameter space
    4. Output is [φ, σ_v] for each sequence in the batch
    
    The network learns to recognize patterns in returns that indicate:
    - Volatility persistence (φ): How clustered volatility is
    - Volatility-of-volatility (σ_v): How jumpy volatility is
    """
    
    def __init__(
        self,
        input_size: int = 1,
        hidden_size: int = 128,
        num_layers: int = 2,
        dropout: float = 0.2,
        sequence_length: int = 252
    ) -> None:
        """Initialize the LSTM estimator."""
        super().__init__()  # type: ignore[no-untyped-call]
        
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.dropout = dropout
        self.sequence_length = sequence_length
        self.output_size = 2  # Always 2 parameters: phi and sigma_v
        
        # LSTM layers for sequence processing
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0.0,
            batch_first=True
        )
        
        # Fully connected layers for parameter estimation
        # Input size is hidden_size (from LSTM output)
        self.fc_layers = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, hidden_size // 4),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 4, self.output_size)
        )
        
        logger.info(
            f"Initialized LSTM estimator: hidden_size={hidden_size}, "
            f"num_layers={num_layers}, dropout={dropout}"
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass through the network.
        
        Parameters
        ----------
        x : torch.Tensor
            Input return sequences of shape (batch_size, sequence_length).
            Returns should be normalized (zero mean, unit variance).
        
        Returns
        -------
        predictions : torch.Tensor
            Estimated parameters of shape (batch_size, 2).
            Columns are [φ, σ_v].
        """
        # Reshaping input for LSTM: (batch_size, seq_len) -> (batch_size, seq_len, 1)
        if x.dim() == 2:
            x = x.unsqueeze(-1)  # Adding feature dimension
        
        # LSTM forward pass
        # Output shape: (batch_size, seq_len, hidden_size)
        lstm_out, _ = self.lstm(x)
        
        # Using the last hidden state (from final timestep)
        # Shape: (batch_size, hidden_size)
        last_hidden = lstm_out[:, -1, :]
        
        # Mapping to parameter space
        # Shape: (batch_size, 2)
        predictions = self.fc_layers(last_hidden)
        
        return predictions


def train_model(
    model: LSTMParameterEstimator,
    train_loader: DataLoader[tuple[torch.Tensor, torch.Tensor]],
    val_loader: DataLoader[tuple[torch.Tensor, torch.Tensor]],
    num_epochs: int = 50,
    learning_rate: float = 0.001,
    device: str | torch.device = "cpu",
    save_path: Path | str | None = None,
    patience: int = 10
) -> dict[str, list[float]]:
    """
    Train the LSTM parameter estimator.
    
    This function implements the complete training loop including:
    - Forward and backward passes
    - Validation monitoring
    - Early stopping
    - Model checkpointing
    - Learning rate scheduling
    
    Parameters
    ----------
    model : LSTMParameterEstimator
        The LSTM model to train.
    train_loader : DataLoader
        DataLoader for training data.
    val_loader : DataLoader
        DataLoader for validation data.
    num_epochs : int, default=50
        Maximum number of training epochs.
    learning_rate : float, default=0.001
        Initial learning rate for Adam optimizer.
    device : str or torch.device, default="cpu"
        Device to train on ("cpu" or "cuda").
    save_path : Path or str or None, default=None
        Path to save the best model checkpoint.
        If None, model is not saved.
    patience : int, default=10
        Number of epochs to wait for validation improvement before early stopping.
    
    Returns
    -------
    history : dict[str, list[float]]
        Training history containing:
        - 'train_loss': List of training losses per epoch
        - 'val_loss': List of validation losses per epoch
    
    Examples
    --------
    >>> from torch.utils.data import DataLoader
    >>> from src.data.synthetic.basic_sv import BasicSVDataGenerator
    >>> 
    >>> # Loading data
    >>> generator = BasicSVDataGenerator(seed=42)
    >>> train_data = generator.load_dataset('data/synthetic/basic_sv/train.npz')
    >>> val_data = generator.load_dataset('data/synthetic/basic_sv/val.npz')
    >>> 
    >>> # Creating datasets
    >>> train_dataset = SVParameterDataset(
    ...     returns=train_data['returns'],
    ...     parameters=train_data['parameters']
    ... )
    >>> val_dataset = SVParameterDataset(
    ...     returns=val_data['returns'],
    ...     parameters=val_data['parameters']
    ... )
    >>> 
    >>> # Creating data loaders
    >>> train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
    >>> val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)
    >>> 
    >>> # Creating and training model
    >>> model = LSTMParameterEstimator(hidden_size=128, num_layers=2)
    >>> history = train_model(
    ...     model=model,
    ...     train_loader=train_loader,
    ...     val_loader=val_loader,
    ...     num_epochs=50,
    ...     save_path='models/lstm_estimator.pt'
    ... )
    """
    device = torch.device(device)
    model = model.to(device)
    
    # Setting up loss function and optimizer
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5
    )
    
    # Training history
    history: dict[str, list[float]] = {'train_loss': [], 'val_loss': []}
    best_val_loss = float('inf')
    patience_counter = 0
    
    logger.info(f"Starting training on {device} for {num_epochs} epochs")
    
    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_batches = 0
        
        for returns, parameters in train_loader:
            returns = returns.to(device)
            parameters = parameters.to(device)
            
            # Forward pass
            optimizer.zero_grad()
            predictions = model(returns)
            loss = criterion(predictions, parameters)
            
            # Backward pass
            loss.backward()
            optimizer.step()  # type: ignore[no-untyped-call]
            
            train_loss += loss.item()
            train_batches += 1
        
        avg_train_loss = train_loss / train_batches
        
        # Validation phase
        model.eval()
        val_loss = 0.0
        val_batches = 0
        
        with torch.no_grad():
            for returns, parameters in val_loader:
                returns = returns.to(device)
                parameters = parameters.to(device)
                
                predictions = model(returns)
                loss = criterion(predictions, parameters)
                
                val_loss += loss.item()
                val_batches += 1
        
        avg_val_loss = val_loss / val_batches
        
        # Recording history
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(avg_val_loss)
        
        # Learning rate scheduling
        scheduler.step(avg_val_loss)  # type: ignore[arg-type]
        
        # Early stopping and checkpointing
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            
            # Saving best model
            if save_path is not None:
                save_path = Path(save_path)
                save_path.parent.mkdir(parents=True, exist_ok=True)
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_loss': avg_val_loss,
                    'train_loss': avg_train_loss,
                }, save_path)
                logger.info(f"Saved best model (val_loss={avg_val_loss:.6f}) to {save_path}")
        else:
            patience_counter += 1
        
        # Logging progress
        if (epoch + 1) % 5 == 0 or epoch == 0:
            logger.info(
                f"Epoch {epoch+1}/{num_epochs} - "
                f"Train Loss: {avg_train_loss:.6f}, "
                f"Val Loss: {avg_val_loss:.6f}, "
                f"LR: {optimizer.param_groups[0]['lr']:.2e}"
            )
        
        # Early stopping
        if patience_counter >= patience:
            logger.info(f"Early stopping at epoch {epoch+1} (patience={patience})")
            break
    
    logger.info(f"Training completed. Best validation loss: {best_val_loss:.6f}")
    
    # Loading best model
    if save_path is not None and Path(save_path).exists():
        checkpoint = torch.load(save_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        logger.info("Loaded best model checkpoint")
    
    return history


def evaluate_model(
    model: LSTMParameterEstimator,
    test_loader: DataLoader[tuple[torch.Tensor, torch.Tensor]],
    device: str | torch.device = "cpu"
) -> dict[str, float]:
    """
    Evaluate the trained model on test data.
    
    Computes various metrics including MSE, MAE, and bias for both parameters.
    
    Parameters
    ----------
    model : LSTMParameterEstimator
        Trained model to evaluate.
    test_loader : DataLoader
        DataLoader for test data.
    device : str or torch.device, default="cpu"
        Device to run evaluation on.
    
    Returns
    -------
    metrics : dict[str, float]
        Dictionary containing:
        - 'mse_phi': Mean squared error for φ
        - 'mse_sigma_v': Mean squared error for σ_v
        - 'mae_phi': Mean absolute error for φ
        - 'mae_sigma_v': Mean absolute error for σ_v
        - 'bias_phi': Bias (mean error) for φ
        - 'bias_sigma_v': Bias (mean error) for σ_v
        - 'mse_total': Total MSE across both parameters
    """
    device = torch.device(device)
    model = model.to(device)
    model.eval()
    
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for returns, parameters in test_loader:
            returns = returns.to(device)
            parameters = parameters.to(device)
            
            predictions = model(returns)
            
            all_predictions.append(predictions.cpu().detach().numpy())  # type: ignore[arg-type]
            all_targets.append(parameters.cpu().detach().numpy())  # type: ignore[arg-type]
    
    # Concatenating all predictions and targets
    predictions: np.ndarray = np.concatenate(all_predictions, axis=0)  # type: ignore[assignment]
    targets: np.ndarray = np.concatenate(all_targets, axis=0)  # type: ignore[assignment]
    
    # Computing metrics
    errors: np.ndarray = predictions - targets  # type: ignore[assignment]
    
    metrics: dict[str, float] = {
        'mse_phi': float(np.mean((errors[:, 0]) ** 2)),  # type: ignore[arg-type]
        'mse_sigma_v': float(np.mean((errors[:, 1]) ** 2)),  # type: ignore[arg-type]
        'mae_phi': float(np.mean(np.abs(errors[:, 0]))),  # type: ignore[arg-type]
        'mae_sigma_v': float(np.mean(np.abs(errors[:, 1]))),  # type: ignore[arg-type]
        'bias_phi': float(np.mean(errors[:, 0])),  # type: ignore[arg-type]
        'bias_sigma_v': float(np.mean(errors[:, 1])),  # type: ignore[arg-type]
        'mse_total': float(np.mean(errors ** 2))  # type: ignore[arg-type]
    }
    
    logger.info("Evaluation metrics:")
    logger.info(f"  MSE (φ): {metrics['mse_phi']:.6f}")
    logger.info(f"  MSE (σ_v): {metrics['mse_sigma_v']:.6f}")
    logger.info(f"  MAE (φ): {metrics['mae_phi']:.6f}")
    logger.info(f"  MAE (σ_v): {metrics['mae_sigma_v']:.6f}")
    logger.info(f"  Bias (φ): {metrics['bias_phi']:.6f}")
    logger.info(f"  Bias (σ_v): {metrics['bias_sigma_v']:.6f}")
    
    return metrics

